{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recency Bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    In prompt engineering, recency bias can affect the way a language model (like GPT) responds to inputs by giving disproportionate weight to the most recent part of the prompt, sometimes neglecting earlier information.\n",
    "    This can skew the model's output if not carefully managed.\n",
    "    This can lead to inaccurate or inconsistent responses that do not take into account the whole context of the task\n",
    "    More specifically, after several experimentations, he found that repeating the main instruction at the end of the prompt can help the model overcome its inner recency bias''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Example: Recency bias in Sentiment Analysis\n",
    "''' \n",
    "      In the context of sentiment analysis using prompt engineering, recency bias can cause the model to give more weight to the sentiment of the most recent part of the text rather than considering the overall sentiment of the entire input. \n",
    "      This can lead to an inaccurate assessment of the sentiment.\n",
    "''' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AHMsE0x6MEMVTQRDvUti5DjGB3KKz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The user expresses disappointment with the decline in quality of a product they have been a long-time fan of. They feel let down by their last purchase, which was particularly disappointing.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1728702866, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=35, prompt_tokens=67, total_tokens=102, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0), prompt_tokens_details={'cached_tokens': 0}))\n",
      "The user expresses disappointment with the decline in quality of a product they have been a long-time fan of. They feel let down by their last purchase, which was particularly disappointing.\n"
     ]
    }
   ],
   "source": [
    "client =  OpenAI()\n",
    "\n",
    "system_message = 'Analyze the sentiment of this text and summarize the users feelings'\n",
    "user_message = \"I've been a long-time fan of this product, and it has always served me well. However, in the last few months,\\\n",
    "                I've noticed a decline in quality, and my last purchase was particularly disappointing.\"\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ]\n",
    ")\n",
    "# print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    Exaplanation: \n",
    "    Here, the model focused primarily on the last sentence, \n",
    "    which expresses disappointment, neglecting the earlier positive sentiment \n",
    "    about being a long-time fan of the product. \n",
    "    This is an example of recency bias, \n",
    "    where the most recent negative sentiment is given disproportionate weight, \n",
    "    resulting in an incomplete sentiment analysis. \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mitigating Recency Bias in Sentiment Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    To address recency bias in prompt engineering, \n",
    "    the prompt can be adjusted to encourage the model to consider the overall sentiment\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client =  OpenAI()\n",
    "\n",
    "## Improved Prompt\n",
    "system_message = '\"Analyze the overall sentiment of this text, taking into account both the positive and negative aspects. Summarize the users feelings.\"'\n",
    "### No change in user_message\n",
    "user_message = \"I've been a long-time fan of this product, and it has always served me well. However, in the last few months,\\\n",
    "                I've noticed a decline in quality, and my last purchase was particularly disappointing.\"\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ]\n",
    ")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall sentiment expressed in this text is mixed. While the user has been a long-time fan of the product and it has served them well in the past (positive aspect), they have noticed a decline in quality recently, with their last purchase being particularly disappointing (negative aspect). The user seems to feel let down by the product's declining quality despite their previous satisfaction.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
